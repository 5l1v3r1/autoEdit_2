<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: frontEnd/autoEdit2API.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: frontEnd/autoEdit2API.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * @file Manages the backend of the app by overwrighting backbone.sync function
 * @author Pietro Passarelli 
 * @requires fs
 * @requires path
 * @requires linvodb
 * @requires level-js
 * @requires interactive_transcription_generator/index.js
 * @todo Write documentation.
 * @todo add error handling and error callbacks
 */

//checking that we are in NWJS enviroment 
// if (window.frontEndEnviromentNWJS) {
  var fs = require("fs")
  var transcription_generate = require("../interactive_transcription_generator/index.js");
  var path = require('path');
  var LinvoDB = require("linvodb3");
  LinvoDB.defaults.store = { db:  require("medeadown") }; //medea level-js
  //TODO:change db with medea
  //+db path, for now in root of app, to be change so that in config where user can set where they want it, but also provide a default. 
  // LinvoDB.dbPath = path.join(process.cwd(), "/db"); 
  LinvoDB.dbPath = window.config.dataPath;

  //setting up transcription model in database.
  var transcriptionModel = "transcription";
  // Non-strict always, can be left empty
  var schema = { }; 
  var options = { };
  var Transcription = new LinvoDB(transcriptionModel, schema, options);

  /**
  * API Object to override Backnone.sync
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  */
  var autoEdit2API = function(method, model, options){
    autoEdit2API[method](model, options.success, options.error)
  }

  /**
  * Create functionality, mapped to REST POST
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  * @returns {object} sucess callback with backbone model containing db id
  */
  autoEdit2API.create = function(model, success, error){
    if( model.constructor.modelType == "transcription"){
      
      var newElement = model.toJSON();
      //create transcription element to save in db 
      var transcription = new Transcription(newElement);
      //save transcription in db
      transcription.save(function(err) {
        //updating backbone with saved transcritpion, containing db id
        model.set(transcription);
        //returning saved transcription callback
        success(model);
      });

      //setting up media folders for media and tmp media on local file system, user libary application support folder 
      var tmpMediaFolder = window.config.dataPath+"/tmp_media";
      var mediaFolder = window.config.dataPath+"/media"
      //if media folder does not exists create it
      if (!fs.existsSync(tmpMediaFolder)){
        console.log("tmpMediaFolder folder not present, creating tmpMediaFolder folder")
          fs.mkdirSync(tmpMediaFolder);
      }else{
        // do nothing, build folder was already there
        console.log("tmpMediaFolder folder was already present")
      }
      //if temp media folder does not exists create it
      if (!fs.existsSync(mediaFolder)){
        console.log("mediaFolder folder not present, creating mediaFolder folder")
          fs.mkdirSync(mediaFolder);
      }else{
        // do nothing, build folder was already there
        console.log("mediaFolder folder was already present")
      }

      // using interactive_transcription_generator to generate metadata, 
      // transcription json 
      // webm video preview 
      transcription_generate({
        id: transcription._id,
        videoUrl: newElement.videoUrl,
        title: newElement.title,
        description: newElement.description,
        //TODO: this is hardcoded, and this variable is not used, fix me!
        // tmpWorkFolder:"/",
        // destFolder:"/media",
        tmpWorkFolder: tmpMediaFolder,
        destFolder: mediaFolder,
        keys: global.keys,
        languageModel: newElement.languageModel,
        sttEngine: newElement.sttEngine,
        cbMetadata:function(respM){
          meta = respM;
          //update current transcription with metadata data
          Transcription.findOne({ _id: transcription._id }, function (err, trs) {
            console.info("got metadata for transcription: "+transcription._id)
            trs.metadata = respM;
            //saving current transcription
            trs.save(function(err) {
              // app.trigger('updateTranscription:'+trs._id);
            });
          });
        },
        cbTranscription: function(resp){
          //updating current transcription with transcription json.
          Transcription.findOne({ _id: resp.id }, function (err, trs) {
            console.info("got transcription json for transcription: "+ trs._id);
            //updating transcription attributes with result
            trs.audioFile = resp.audioFile;
            trs.processedAudio = resp.processedAudio;
            trs.text = resp.text;
            trs.status = resp.status;
            //saving current transcription 
            trs.save(function(err) {
              // app.trigger('updateTranscription:'+trs._id);
            });
          });
        },
        cbVideo: function(resp){
          //updating current transcription with webm html5 video preview.
          Transcription.findOne({ _id: transcription._id}, function (err, trs) {
            console.info("got video webm back for transcription: "+ trs._id);
            //updating transcription attributes with result
            trs.videoOgg = resp.videoOgg;
            trs.processedVideo = resp.processedVideo;
            //saving current transcription 
            trs.save(function(err) {
              // app.trigger('updateTranscription:'+trs._id);
            });
          });
        }
      });
    }
  }

  /**
  * Read functionality,Find all  and fine One, mapped to REST GET
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  * @returns {object} sucess callback with backbone model
  */
  autoEdit2API.read = function(model, success, error){
    //If a colleciton
    if (model.models) {
      console.info("Collection:" +model.constructor.modelType )
      //for transcription model
      if( model.constructor.modelType == "transcriptions"){
        //look in database
        Transcription.find({}, function (err, transcriptions) {
          //return transcription collection 
          success(transcriptions);
        });
      }//if transcription collection
    }else {
      //if a model 
      console.info("Model: "+model.constructor.modelType)
      //for transcription model
      if(model.constructor.modelType == "transcription"){
        //looks in database using transcription id
        Transcription.findOne({ _id: model._id }, function (err, transcription) {     
            //return transcription model
            success(transcription)
        });
      }
    }
  }

  /**
  * Update functionality, mapped to REST PUT
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  * @returns {object} sucess callback with backbone model
  */
  autoEdit2API.update = function(model, success, error){
    //for transcription model
    if(model.constructor.modelType == "transcription"){
      //looks in database using transcription id
      Transcription.findOne({ _id: model.get("_id") }, function(err, doc) {
        //TODO: there's got to be a better way to do this
        //NOTE: rather then using update, which did not seemed to be optimised for speed.
        //uses `findOne`, replaces attributes with new once.
        doc.text                = model.attributes.text;
        doc.languageModel       = model.attributes.languageModel;
        doc.counterForPaperCuts = model.attributes.counterForPaperCuts;
        doc.processedAudio      = model.attributes.processedAudio;
        doc.processedVideo      = model.attributes.processedVideo;
        doc.status              = model.attributes.status;
        doc.highlights          = model.attributes.highlights;
        doc.title               = model.attributes.title;
        doc.videoUrl            = model.attributes.videoUrl;
        doc.sttEngine           = model.attributes.sttEngine;
        doc.audioFile           = model.attributes.audioFile;
        doc.metadata            = model.attributes.metadata;
        //saving transcription to database
        doc.save(function(err) {
          //returning sucess callback with backbone model to client side
          success(model);
        });
      });
    } 
  }

  /**
  * Patch functionality, mapped to REST PUT
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  * @returns {object} sucess callback with backbone model
  */
  autoEdit2API.patch = function(model, success, error){
    if(model.constructor.modelType == "transcription"){
       Transcription.findOne({ _id: model.get("_id") }, function(err, doc) {
        //TODO: there's got to be a better way to do this
        doc.text                = model.attributes.text;
        doc.languageModel       = model.attributes.languageModel;
        doc.counterForPaperCuts = model.attributes.counterForPaperCuts;
        doc.processedAudio      = model.attributes.processedAudio;
        doc.processedVideo      = model.attributes.processedVideo;
        doc.status              = model.attributes.status;
        doc.highlights          = model.attributes.highlights;
        doc.title               = model.attributes.title;
        doc.videoUrl            = model.attributes.videoUrl;
        doc.sttEngine           = model.attributes.sttEngine;
        doc.audioFile           = model.attributes.audioFile;
        doc.metadata            = model.attributes.metadata;

        doc.save(function(err) {
          success(model);
        });
      });
    }
  }

  /**
  * Delete functionality, mapped to REST Delete
  * @param {object} method - Backbone RESTfull method request.
  * @param {object} model - Backbone model being handled.
  * @param {object} options - Sucess or failure callback.
  * @returns {object} sucess callback with backbone model
  */
  autoEdit2API.delete = function(model, success, error){
    ///for transcription model
    if(model.constructor.modelType == "transcription"){
      //looks in database using transcription id
      //worth looking into alternative
      //https://github.com/Ivshti/linvodb3#removing-from-the-collection 
      //Transcription.remove({ _id: model._id }, {multi: false }, function (err, numRemoved) {
      // numRemoved = 1
      // removed done
      // });
      Transcription.findOne(model._id, function(err, transcription) {
        //deletes transcription from db
        transcription.remove(function() {
          //removing media associated with transcription.
          //TODO: this only deletes the video if the video has done processing.
          // this means incomplete vidoes are left in the folder if the transcription is deleted
          if(model.attributes.processedVideo){
            fs.unlinkSync( model.attributes.videoOgg);     
          }
          //if the trascription has been shown the audio will always be present because is needed to generate the text transcription
            fs.unlinkSync( model.attributes.audioFile); 
          //returns sucess callback
          success(model);
        });//remove 
      });//find
    }//if transcription
  }

  module.exports = autoEdit2API;
// }//if in NWJS enviroment 



</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="EDL.html">EDL</a></li></ul><h3>Global</h3><ul><li><a href="global.html#addsinfoontrimmedclipstolistoffiles.">adds info on trimmed clips to list of files.</a></li><li><a href="global.html#autoEdit2API">autoEdit2API</a></li><li><a href="global.html#convertTakesinaconfigobjectwithpropreties:src,outputName,ffmpegBinandoptionalcallback.">convert
Takes in a config object with propreties: src, outputName, ffmpegBin and optional callback.</a></li><li><a href="global.html#convertToWav">convertToWav</a></li><li><a href="global.html#createSrtContent">createSrtContent</a></li><li><a href="global.html#fromSeconds">fromSeconds</a></li><li><a href="global.html#fromSecondsForSrt">fromSecondsForSrt</a></li><li><a href="global.html#fs">fs</a></li><li><a href="global.html#getFileName">getFileName</a></li><li><a href="global.html#makePaperEdit">makePaperEdit</a></li><li><a href="global.html#nw">nw</a></li><li><a href="global.html#padNumber">padNumber</a></li><li><a href="global.html#parse">parse</a></li><li><a href="global.html#send_to_gentle">send_to_gentle</a></li><li><a href="global.html#SendToWatson">SendToWatson</a></li><li><a href="global.html#splitsanaudiofile,ifitexceeds5minutes,in5minutesintervalls.usingffprobetoreadduration.ffmpegpassedtotrimmermodule.savestrimmedclipsintempfolder">splits an audio file, if it exceeds 5 minutes, in 5 minutes intervalls.  
using ffprobe to read duration. ffmpeg passed to trimmer module.
saves trimmed clips in temp folder</a></li><li><a href="global.html#toSeconds">toSeconds</a></li><li><a href="global.html#transcribeTakesinthefilepathtoamediaaudioorvideofileandreturnsajsonoftranscription.convertsaudioormediafileintoaudiomeetingIBMSpecsdividesaudiotosendtoSTTAPIinto5minchunkssendsallclipsallatoncereconnectsresultsasreturnedbySTTAPIintoonejsonfilethatmeetstheautoEdit2specsreturnsthatascallback">transcribe
Takes in the file path to a media audio or video file and returns a json of transcription.
converts audio or media file into audio meeting IBM Specs
divides audio to send to STT API into 5 min chunks
sends all clips all at once 
reconnects results as returned by STT API into one json file that meets the autoEdit2 specs
returns that as callback</a></li><li><a href="global.html#trim">trim</a></li><li><a href="global.html#watson">watson</a></li><li><a href="global.html#%257Bstirng%257DEDL-andEDLstringforanEDLline.">{stirng} EDL - and EDL string  for an EDL line.</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.4.2</a> on Tue Oct 18 2016 10:41:31 GMT-0400 (EDT)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
